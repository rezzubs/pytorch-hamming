"""Protection for a most significant bit"""

from __future__ import annotations

import logging
from dataclasses import dataclass
from typing import override

import hamming_core
import torch
from torch import Tensor

from pytorch_hamming.encoding._tensor import TensorEncoderHelper, TensorEncodingHelper
from pytorch_hamming.encoding.sequence import TensorEncoding

_logger = logging.getLogger(__name__)


class MsbEncoder(TensorEncoderHelper):
    @override
    def encode_float32(self, t: Tensor) -> Tensor:
        with torch.no_grad():
            t_np = t.numpy(force=True)
        hamming_core.bit30_encode_f32(t_np)
        return torch.from_numpy(t_np)  # pyright: ignore[reportUnknownMemberType]

    @override
    def encode_float16(self, t: Tensor) -> Tensor:
        with torch.no_grad():
            t_np = t.view(torch.uint16).numpy(force=True)
        hamming_core.bit14_encode_u16(t_np)
        return torch.from_numpy(t_np).view(torch.float16)  # pyright: ignore[reportUnknownMemberType]

    @override
    def create_encoding(
        self,
        data: list[Tensor],
        bits_count: int,
        decoded_tensors: list[Tensor],
        dtype: torch.dtype,
    ) -> TensorEncoding:
        return MsbEncoding(data, bits_count, decoded_tensors, dtype)

    @override
    def encoder_add_metadata(self, metadata: dict[str, str]) -> None:
        metadata["msb_duplicated"] = "true"


@dataclass
class MsbEncoding(TensorEncodingHelper):
    """An encoding format for protecting the most significant bits of parameter tensors.

    Most significant in this case referres to the second highest bit â€” the one
    after the sign bit. That bit will be copied to the lowest bits and those
    will be used to recover from single-bit errors.
    """

    _encoded_data: list[Tensor]
    _bits_count: int
    _decoded_tensors: list[Tensor]
    _dtype: torch.dtype
    _needs_recompute: bool = True

    @override
    def decode_float16(self, t: Tensor) -> Tensor:
        encoded_np = t.view(torch.uint16).numpy(force=True)
        hamming_core.bit14_decode_u16(encoded_np)
        return torch.from_numpy(encoded_np).view(torch.float16)  # pyright: ignore[reportUnknownMemberType]

    @override
    def decode_float32(self, t: Tensor) -> Tensor:
        encoded_np = t.numpy(force=True)
        hamming_core.bit30_decode_f32(encoded_np)
        return torch.from_numpy(encoded_np)  # pyright: ignore[reportUnknownMemberType]
